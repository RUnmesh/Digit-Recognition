{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "*****\n",
    "### Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project will use a One-vs-All classifier to recognize hand-written digits.\n",
    "\n",
    "MINST database has been used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0\n",
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "from array import array\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_loader():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        self.train_img_file = 'Loader/data/train-images-idx3-ubyte'\n",
    "        self.train_labels_file = 'Loader/data/train-labels-idx1-ubyte'\n",
    "\n",
    "        self.test_img_file = 'Loader/data/t10k-images-idx3-ubyte'\n",
    "        self.test_labels_file = 'Loader/data/t10k-labels-idx1-ubyte'\n",
    "\n",
    "        self.train_img = []\n",
    "        self.train_label = []\n",
    "\n",
    "        self.test_img = []\n",
    "        self.test_label = []\n",
    "\n",
    "    def load(load , img_path , label_path) :\n",
    "\n",
    "        with open(img_path , 'rb') as image_file:\n",
    "            magic , size , rows , cols = struct.unpack('>IIII' , image_file.read(4*4))\n",
    "            image_data = array('B' , image_file.read())\n",
    "\n",
    "        img_size = rows*cols\n",
    "        images = []\n",
    "\n",
    "        for i in range(size) :\n",
    "            image = image_data[i*img_size : (i+1)*img_size]\n",
    "            images.append(image)\n",
    "\n",
    "        with open(label_path , 'rb') as label_file :\n",
    "            magic , size = struct.unpack('>II' , label_file.read(2*4))\n",
    "            labels = array('B' , label_file.read())\n",
    "\n",
    "        return images , labels\n",
    "\n",
    "    def load_training(self) :\n",
    "        self.train_img , self.train_label = self.load(os.path.join( os.getcwd() ,self.train_img_file) , \n",
    "                                                                    os.path.join( os.getcwd() ,self.train_labels_file))\n",
    "    \n",
    "    def load_test(self) :\n",
    "        self.test_img , self.test_label = self.load(os.path.join( os.getcwd() ,self.test_img_file) , \n",
    "                                                                    os.path.join( os.getcwd() ,self.test_labels_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_load() :\n",
    "    data = data_loader()\n",
    "\n",
    "    data.load_training()\n",
    "    data.load_test()\n",
    "\n",
    "    X_train = np.array(data.train_img , dtype=np.float) / 255\n",
    "    y_train = np.array(data.train_label , dtype=np.int)\n",
    "\n",
    "    X_test = np.array(data.test_img , dtype=np.float) / 255\n",
    "    y_test = np.array(data.test_label , dtype=np.int)\n",
    "\n",
    "    print(\"Number of training examples = \" , X_train.shape[0])\n",
    "    print(\"Number of test examples = \" , X_test.shape[0])\n",
    "    print(f'Image size = {math.sqrt(X_train.shape[1])} x {math.sqrt(X_train.shape[1])}')\n",
    "    \n",
    "    X_train = np.hstack(( np.ones(( X_train.shape[0] , 1 )) , X_train ))\n",
    "    X_test = np.hstack(( np.ones(( X_test.shape[0] , 1 )) , X_test ))\n",
    "\n",
    "    np.save('./Reg_Data/Xtrain.npy' , X_train)\n",
    "    np.save('./Reg_Data/ytrain.npy' , y_train)\n",
    "    np.save('./Reg_Data/Xtest.npy' , X_test)\n",
    "    np.save('./Reg_Data/ytest.npy' , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the above function will store the data in .npy files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example has 784 features normalised between 0 to 1 and an integer label representing the class. The features represent a 28 X 28 pixel grayscale image of a digit.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "y_train = np.load('./Reg_Data/ytrain.npy')\n",
    "X_train = np.load('./Reg_Data/Xtrain.npy')\n",
    "\n",
    "size=np.zeros(10)\n",
    "labels=[0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "for i in y_train:\n",
    "    size[i] += 1\n",
    "\n",
    "fig,axes = plt.subplots(1 , 2)\n",
    "axes[0].pie(size , labels=labels)\n",
    "axes[0].axis('equal')\n",
    "\n",
    "randimg = np.copy(X_train[random.randint(0,X_train.shape[0])])\n",
    "randimg = randimg[1:].reshape(28,28)\n",
    "\n",
    "imgplot = axes[1].imshow(randimg , cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set is pretty evenly distributed among the ten classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Design and test a model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the cost function and gradient need to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z) :\n",
    "    return 1 / ( 1 + np.exp(-z) )\n",
    "\n",
    "def costfunction( theta , X , y , lmbda):\n",
    "    \n",
    "    z = np.dot( X , theta)\n",
    "    hypothesis = sigmoid(z)\n",
    "\n",
    "    temp1 = np.multiply( y , np.log(hypothesis) )\n",
    "    temp2 = np.multiply( 1 - y , np.log(1 - hypothesis) )\n",
    "    reg = (lmbda / 2) * np.sum(theta[1:] ** 2)\n",
    "\n",
    "    J = ( - np.sum( temp1 + temp2 ) + reg ) / X.shape[0]\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def gradient( theta , X , y , lmbda) :\n",
    "\n",
    "    z = np.dot( X , theta )\n",
    "    diff = sigmoid(z) - y\n",
    "\n",
    "    grad = np.dot( X.T , diff ) + (lmbda/2) * theta\n",
    "    grad[0] -= (lmbda/2) * theta[0]\n",
    "\n",
    "    return (grad / X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fmin_cg optimizer funtion in scipy , the cost function will be minimized. Initially the value of lambda will be set to zero. The optimum value of lambda will be searched for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros(( 10 , X_train.shape[1] ))\n",
    "lmbda = 0\n",
    "\n",
    "for i in range(10) :\n",
    "    theta[i] = optimize.fmin_cg( f = costfunction , x0 = theta[i] , fprime = gradient , maxiter = 1000 , args = (X_train , ((y_train == i).astype(np.int)).flatten() , lmbda))\n",
    "\n",
    "np.save('./Reg_Data/trained_theta.npy' , theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_error(X , y , theta) :\n",
    "    pred_y = np.argmax( X@theta.T , axis = 1)\n",
    "    error = np.mean((y==pred_y).astype(int))*100 \n",
    "    \n",
    "    return 100 - error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_error = calc_error(X_train , y_train , theta)\n",
    "\n",
    "y_test = np.load('./Reg_Data/ytest.npy')\n",
    "X_test = np.load('./Reg_Data/Xtest.npy')\n",
    "\n",
    "test_error = calc_error(X_test , y_test , theta)\n",
    "\n",
    "print(f'Training error = {train_error}')\n",
    "print(f'Test error = {test_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the above model, a better value of regularization constant needs to be searched for. For this purpose, a validation set is created from the test set. Different values of the regularization constant will be tried and the one with minimum cross-validation error will be further tested on rest of test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poss_lmbda = [0.01 , 0.03 , 0.1 , 0.3 , 1 , 3 , 10 , 30]\n",
    "temp_theta = np.zeros(( len(poss_lmbda) , 10 , X_test.shape[1] ))\n",
    "errors = np.zeros(len(poss_lmbda))\n",
    "\n",
    "X_cv = np.copy(X_test[:5000])\n",
    "y_cv = np.copy(y_test[:5000])\n",
    "\n",
    "for i in range(len(poss_lmbda)) :\n",
    "    for j in range(10) :\n",
    "        temp_theta[i][j] = optimize.fmin_cg( f = costfunction , x0 = temp_theta[i][j] , fprime = gradient , maxiter = 1000 , args = (X_train , ((y_train == i).astype(np.int)).flatten() , poss_lmbda[i]))\n",
    "    errors[i] = calc_error(X_cv , y_cv , temp_theta[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig , axes = plt.subplots()\n",
    "axes.plot(poss_lmbda , errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, the optimum value of the regularization constant is about 0.01.\n",
    "For the final step, using the theta for this value of the constant, the model will be tested on the remaining test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = temp_theta[argmin(errors)]\n",
    "np.save('./Reg_Data/trained_theta.npy' , theta)\n",
    "\n",
    "test_error = calc_error(X_test[5000: , 1:] , y_test[5000:] , theta)\n",
    "\n",
    "print(f'Test error = {test_error}')\n",
    "\n",
    "randimg = np.copy(X_train[random.randint(0,X_train.shape[0])])\n",
    "prediction = np.argmax(theta @ randimg)\n",
    "\n",
    "fig,axe = plt.subplots()\n",
    "imgplot = axe.imshow(randimg[1:].reshape(28,28) , cmap='gray')\n",
    "plt.title(prediction , fontsize = 'large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 - 2 Layer Neural Network\n",
    "\n",
    "### Back to Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
